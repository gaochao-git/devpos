#!/usr/bin/env python3
"""
ğŸ”¥ é˜²ç«å¢™æµé‡ä¸ä¸šåŠ¡å“åº”å…³è”åˆ†æè„šæœ¬ (ç®€åŒ–ç‰ˆ)

ç”¨æ³•:
  æ¨¡å¼1 - æŒ‡å®šæ—¶é—´çª—å£: python firewall_simple_monitor.py <IP> <æ—¶é—´çª—å£ç§’æ•°>
  æ¨¡å¼2 - æŒ‡å®šæ—¶é—´èŒƒå›´: python firewall_simple_monitor.py <IP> <å¼€å§‹æ—¶é—´> <ç»“æŸæ—¶é—´>
  
ç¤ºä¾‹:
  python firewall_simple_monitor.py 192.168.1.1 3600
  python firewall_simple_monitor.py 192.168.1.1 "2024-01-15 10:00:00" "2024-01-15 12:00:00"
  
è¯´æ˜:
  - æ—¶é—´èŒƒå›´æœ€å¤šæ”¯æŒ6å°æ—¶
  - æ—¶é—´æ ¼å¼: YYYY-MM-DD HH:MM:SS
"""

import sys
from datetime import datetime, timedelta
import requests
from typing import Dict, List, Tuple

# é…ç½®
CONFIG = {
    "max_bandwidth_bps": 40 * 1000 * 1000,  # 40Gbpsæœ€å¤§å¸¦å®½
    "traffic_baseline_bps": 5 * 1000 * 1000,  # 5MbpsåŸºçº¿
    "db_response_baseline_ms": 4,  # 4msåŸºçº¿
    "max_time_range_hours": 6  # æœ€å¤§æ—¶é—´èŒƒå›´6å°æ—¶
}

# IPåˆ°æœºæˆ¿çš„æ˜ å°„å…³ç³»
IP_TO_DATACENTER = {
    "192.168.1.1": "IDC1",
    "192.168.1.2": "IDC1", 
    "10.0.0.1": "IDC2",
    "10.0.0.2": "IDC2",
    "172.16.0.1": "IDC3",
    "172.16.0.2": "IDC3",
    # å¯ä»¥ç»§ç»­æ·»åŠ æ›´å¤šIPæ˜ å°„
}

TRAFFIC_METRICS = {
    "inbound_traffic": "net.if.in[eth0]",
    "outbound_traffic": "net.if.out[eth0]",
}

BUSINESS_METRICS = {
    "database_response": "db.commit.rt"
}

def log_message(message, level="INFO"):
    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    print(f"[{timestamp}] [{level}] {message}")

def get_metrics_data(host_ip: str, metrics: Dict[str, str], time_from: datetime, time_till: datetime) -> Dict[str, List]:
    """è·å–æŒ‡æ ‡æ•°æ®"""
    try:
        from zabbix_api_util import get_zabbix_metrics
        
        time_from_ts = int(time_from.timestamp())
        time_till_ts = int(time_till.timestamp())
        
        metrics_data = {}
        
        for metric_name, metric_key in metrics.items():
            result = get_zabbix_metrics(
                host_ip=host_ip,
                metric_name=metric_key,
                time_from=time_from_ts,
                time_till=time_till_ts,
                match_type='search',
                limit=3600
            )
            
            if result['status'] == 'success' and result['data']:
                data = []
                for item in result['data']:
                    try:
                        data.append({
                            'time': datetime.fromtimestamp(int(item['clock'])),
                            'value': float(item['value'])
                        })
                    except (ValueError, KeyError):
                        continue
                
                metrics_data[metric_name] = sorted(data, key=lambda x: x['time'])
                log_message(f"æŒ‡æ ‡ {metric_name} è·å–æˆåŠŸ, æ•°æ®ç‚¹: {len(data)}")
            else:
                metrics_data[metric_name] = []
                log_message(f"æŒ‡æ ‡ {metric_name} è·å–å¤±è´¥", "ERROR")
        
        return metrics_data
        
    except Exception as e:
        log_message(f"è·å–æŒ‡æ ‡æ•°æ®å¤±è´¥: {e}", "ERROR")
        return {}

def format_traffic_rate(bps: float) -> str:
    """æ ¼å¼åŒ–æµé‡æ˜¾ç¤º"""
    if bps >= 1000**3:
        return f"{bps/(1000**3):.2f} Gbps"
    elif bps >= 1000**2:
        return f"{bps/(1000**2):.2f} Mbps"
    elif bps >= 1000:
        return f"{bps/1000:.2f} Kbps"
    else:
        return f"{bps:.2f} bps"

def identify_traffic_increase_intervals(data: List[Dict]) -> List[Dict]:
    """è¯†åˆ«æµé‡é€’å¢åŒºé—´"""
    if not data or len(data) < 3:
        return []
    
    increase_intervals = []
    current_interval = None
    
    for i in range(1, len(data)):
        prev_value = data[i-1]['value']
        curr_value = data[i]['value']
        
        if curr_value > prev_value:  # æµé‡é€’å¢
            if current_interval is None:
                current_interval = {
                    'start_time': data[i-1]['time'],
                    'end_time': data[i]['time'],
                    'start_value': prev_value,
                    'end_value': curr_value,
                    'peak_value': curr_value
                }
            else:
                current_interval['end_time'] = data[i]['time']
                current_interval['end_value'] = curr_value
                current_interval['peak_value'] = max(current_interval['peak_value'], curr_value)
        else:
            if current_interval is not None:
                # è®¡ç®—é€’å¢å¹…åº¦å’ŒæŒç»­æ—¶é—´
                increase_ratio = (current_interval['end_value'] - current_interval['start_value']) / current_interval['start_value'] if current_interval['start_value'] > 0 else 0
                duration = (current_interval['end_time'] - current_interval['start_time']).total_seconds()
                
                if increase_ratio > 0.1 or duration > 30:  # å¢é•¿è¶…è¿‡10%æˆ–æŒç»­è¶…è¿‡30ç§’
                    current_interval['increase_ratio'] = increase_ratio
                    current_interval['duration_seconds'] = duration
                    increase_intervals.append(current_interval)
                
                current_interval = None
    
    # å¤„ç†æœ€åä¸€ä¸ªåŒºé—´
    if current_interval is not None:
        increase_ratio = (current_interval['end_value'] - current_interval['start_value']) / current_interval['start_value'] if current_interval['start_value'] > 0 else 0
        duration = (current_interval['end_time'] - current_interval['start_time']).total_seconds()
        
        if increase_ratio > 0.1 or duration > 30:
            current_interval['increase_ratio'] = increase_ratio
            current_interval['duration_seconds'] = duration
            increase_intervals.append(current_interval)
    
    return increase_intervals

def analyze_traffic_trend(data: List[Dict]) -> Dict:
    """åˆ†ææµé‡è¶‹åŠ¿"""
    if not data or len(data) < 3:
        return {
            "is_increasing": False,
            "max_bps": 0,
            "avg_bps": 0,
            "trend": "insufficient_data",
            "increase_intervals": []
        }
    
    values = [item['value'] for item in data]
    max_bps = max(values)
    avg_bps = sum(values) / len(values)
    
    # ç›´æ¥è¯†åˆ«æ‰€æœ‰é€’å¢åŒºé—´
    all_increase_intervals = identify_traffic_increase_intervals(data)
    
    # ç­›é€‰å‡ºæœ€å¤§å€¼è¶…è¿‡åŸºå‡†å€¼çš„é€’å¢åŒºé—´
    significant_intervals = []
    for interval in all_increase_intervals:
        if interval['peak_value'] > CONFIG["traffic_baseline_bps"]:
            significant_intervals.append(interval)
    
    # æ ¹æ®æ˜¯å¦æœ‰è¶…è¿‡åŸºå‡†å€¼çš„é€’å¢åŒºé—´æ¥åˆ¤æ–­è¶‹åŠ¿
    is_increasing = len(significant_intervals) > 0
    trend = "increasing" if is_increasing else "normal"
    
    return {
        "is_increasing": is_increasing,
        "max_bps": max_bps,
        "avg_bps": avg_bps,
        "trend": trend,
        "increase_intervals": significant_intervals  # åªè¿”å›è¶…è¿‡åŸºå‡†å€¼çš„åŒºé—´
    }

def analyze_response_trend(data: List[Dict]) -> Dict:
    """åˆ†æå“åº”æ—¶é—´è¶‹åŠ¿"""
    if not data or len(data) < 3:
        return {
            "is_degrading": False,
            "avg_ms": 0,
            "max_ms": 0,
            "trend": "insufficient_data"
        }
    
    values = [item['value'] for item in data]
    avg_ms = sum(values) / len(values)
    max_ms = max(values)
    
    # ç›´æ¥è¯†åˆ«æ‰€æœ‰å“åº”æ—¶é—´é€’å¢åŒºé—´
    all_increase_intervals = identify_traffic_increase_intervals(data)  # å¤ç”¨é€’å¢åŒºé—´è¯†åˆ«å‡½æ•°
    
    # ç­›é€‰å‡ºæœ€å¤§å€¼è¶…è¿‡åŸºå‡†å€¼çš„é€’å¢åŒºé—´
    significant_intervals = []
    for interval in all_increase_intervals:
        if interval['peak_value'] > CONFIG["db_response_baseline_ms"]:
            significant_intervals.append(interval)
    
    # æ ¹æ®æ˜¯å¦æœ‰è¶…è¿‡åŸºå‡†å€¼çš„é€’å¢åŒºé—´æ¥åˆ¤æ–­æ˜¯å¦æ¶åŒ–
    is_degrading = len(significant_intervals) > 0
    trend = "degrading" if is_degrading else "normal"
    
    return {
        "is_degrading": is_degrading,
        "avg_ms": avg_ms,
        "max_ms": max_ms,
        "trend": trend
    }

def get_mock_response_data(host_ip: str, time_from: datetime, time_till: datetime) -> Dict[str, List]:
    """ç”Ÿæˆmockä¸šåŠ¡å“åº”æ•°æ®"""
    import random
    
    duration_seconds = int((time_till - time_from).total_seconds())
    data_points = max(3, duration_seconds // 30)
    
    base_db_time = 15
    db_response_data = []
    
    for i in range(data_points):
        time_point = time_from + timedelta(seconds=i * 30)
        
        if random.random() < 0.3:  # 30%æ¦‚ç‡æ¨¡æ‹Ÿå“åº”æ—¶é—´æ¶åŒ–
            degradation_factor = 1 + (i / data_points) * 3
            db_time = base_db_time * degradation_factor + random.uniform(-5, 15)
        else:
            db_time = base_db_time + random.uniform(-8, 20)
        
        db_response_data.append({
            'time': time_point,
            'value': max(1, db_time)
        })
    
    return {"database_response": db_response_data}

def analyze_interval_impact(host_ip: str, interval: Dict) -> Dict:
    """åˆ†æåŒºé—´ä¸šåŠ¡å½±å“"""
    business_data = get_mock_response_data(host_ip, interval['start_time'], interval['end_time'])
    
    if not business_data or 'database_response' not in business_data:
        return {"has_impact": False, "analysis": None}
    
    response_analysis = analyze_response_trend(business_data['database_response'])
    
    return {
        "has_impact": response_analysis['is_degrading'],
        "analysis": response_analysis
    }

def generate_report(datacenter: str, host_ip: str, time_window: int, impact_intervals: List[Dict], traffic_data: Dict, time_from: datetime, time_till: datetime):
    """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
    
    # è®¡ç®—åŸºå‡†å€¼ç”¨äºæ˜¾ç¤º
    traffic_baseline_mbps = CONFIG["traffic_baseline_bps"] / (1000 * 1000)
    db_baseline_ms = CONFIG["db_response_baseline_ms"]
    
    # ç»Ÿè®¡æ•°æ®ç‚¹æ•°
    inbound_points = len(traffic_data.get('inbound_traffic', []))
    outbound_points = len(traffic_data.get('outbound_traffic', []))
    
    # è®¡ç®—å“åº”æ—¶é—´æ•°æ®ç‚¹æ•°ï¼ˆåŸºäºç¬¬ä¸€ä¸ªå½±å“åŒºé—´çš„mockæ•°æ®ï¼‰
    response_points = 0
    if impact_intervals:
        # ä½¿ç”¨ç¬¬ä¸€ä¸ªåŒºé—´çš„æ—¶é—´èŒƒå›´æ¥ä¼°ç®—å“åº”æ—¶é—´æ•°æ®ç‚¹æ•°
        first_interval = impact_intervals[0]
        duration_seconds = int((first_interval['end_time'] - first_interval['start_time']).total_seconds())
        response_points = max(3, duration_seconds // 30)  # æ¯30ç§’ä¸€ä¸ªç‚¹ï¼Œæœ€å°‘3ä¸ªç‚¹
    
    print(f"""
é˜²ç«å¢™æµé‡é€’å¢åŒºé—´å½±å“åˆ†æ
============================================================
æœºæˆ¿: {datacenter}
é˜²ç«å¢™IP: {host_ip}
æµé‡åˆ†æåŸºå‡†å€¼: > {traffic_baseline_mbps:.0f} Mbps
æ•°æ®åº“å“åº”åˆ†æåŸºå‡†å€¼: > {db_baseline_ms} ms
åˆ†ææ—¶é—´çª—å£: {time_window}ç§’ ({time_from.strftime('%Y-%m-%d %H:%M:%S')} ~ {time_till.strftime('%Y-%m-%d %H:%M:%S')})
å…¥æµé‡æ•°æ®ç‚¹æ•°: {inbound_points}
å‡ºæµé‡æ•°æ®ç‚¹æ•°: {outbound_points}
å“åº”è€—æ—¶æ•°æ®ç‚¹æ•°: {response_points}
""")
    
    if not impact_intervals:
        print("ç»“è®ºï¼šæ— æµé‡é€’å¢åŒºé—´å¯¹ä¸šåŠ¡é€ æˆå½±å“")
        return
    
    # ç”Ÿæˆç»¼åˆå½±å“åˆ†æ
    generate_comprehensive_assessment(impact_intervals)

def generate_comprehensive_assessment(impact_intervals: List[Dict]):
    """ç”Ÿæˆç»¼åˆå½±å“åˆ†æ"""
    print("\nç»¼åˆå½±å“åˆ†æ:")
    
    # åˆ†åˆ«ç»Ÿè®¡å…¥ç«™æµé‡ã€å‡ºç«™æµé‡
    inbound_intervals = [i for i in impact_intervals if i['traffic_type'] == 'inbound']
    outbound_intervals = [i for i in impact_intervals if i['traffic_type'] == 'outbound']
    
    # å…¥ç«™æµé‡åˆ†æ
    if inbound_intervals:
        max_inbound_increase = max(interval['increase_ratio'] * 100 for interval in inbound_intervals)
        max_inbound_interval = max(inbound_intervals, key=lambda x: x['increase_ratio'])
        max_inbound_peak_interval = max(inbound_intervals, key=lambda x: x['peak_value'])
        
        print(f"""  ã€å…¥ç«™æµé‡ã€‘
    æœ€å¤§æµé‡å¢é•¿ç‡: {max_inbound_increase:.1f}% æµé‡å˜åŒ–: {format_traffic_rate(max_inbound_interval['start_value'])} -> {format_traffic_rate(max_inbound_interval['end_value'])} å‘ç”Ÿæ—¶é—´: {max_inbound_interval['start_time'].strftime('%Y-%m-%d %H:%M:%S')} ~ {max_inbound_interval['end_time'].strftime('%Y-%m-%d %H:%M:%S')}
    æœ€å¤§æµé‡å€¼: {format_traffic_rate(max_inbound_peak_interval['peak_value'])} å‘ç”Ÿæ—¶é—´: {max_inbound_peak_interval['start_time'].strftime('%Y-%m-%d %H:%M:%S')} ~ {max_inbound_peak_interval['end_time'].strftime('%Y-%m-%d %H:%M:%S')}""")
    else:
        print("  ã€å…¥ç«™æµé‡ã€‘æ— å¼‚å¸¸åŒºé—´")
    
    # å‡ºç«™æµé‡åˆ†æ
    if outbound_intervals:
        max_outbound_increase = max(interval['increase_ratio'] * 100 for interval in outbound_intervals)
        max_outbound_interval = max(outbound_intervals, key=lambda x: x['increase_ratio'])
        max_outbound_peak_interval = max(outbound_intervals, key=lambda x: x['peak_value'])
        
        print(f"""  ã€å‡ºç«™æµé‡ã€‘
    æœ€å¤§æµé‡å¢é•¿ç‡: {max_outbound_increase:.1f}% æµé‡å˜åŒ–: {format_traffic_rate(max_outbound_interval['start_value'])} -> {format_traffic_rate(max_outbound_interval['end_value'])} å‘ç”Ÿæ—¶é—´: {max_outbound_interval['start_time'].strftime('%Y-%m-%d %H:%M:%S')} ~ {max_outbound_interval['end_time'].strftime('%Y-%m-%d %H:%M:%S')}
    æœ€å¤§æµé‡å€¼: {format_traffic_rate(max_outbound_peak_interval['peak_value'])} å‘ç”Ÿæ—¶é—´: {max_outbound_peak_interval['start_time'].strftime('%Y-%m-%d %H:%M:%S')} ~ {max_outbound_peak_interval['end_time'].strftime('%Y-%m-%d %H:%M:%S')}""")
    else:
        print("  ã€å‡ºç«™æµé‡ã€‘æ— å¼‚å¸¸åŒºé—´")
    
    # æ•°æ®åº“å“åº”è€—æ—¶åˆ†æ
    print("  ã€æ•°æ®åº“å“åº”è€—æ—¶ã€‘")
    
    # è®¡ç®—æœ€å¤§å“åº”æ—¶é—´æ¶åŒ–
    max_response_degradation = 0
    max_response_interval = None
    max_response_earlier_avg = 0
    max_response_recent_avg = 0
    max_response_ms = 0
    max_response_ms_interval = None
    
    for interval in impact_intervals:
        business_impact = interval['business_impact']
        analysis = business_impact['analysis']
        
        # æ‰¾åˆ°æœ€å¤§å“åº”æ—¶é—´
        if analysis['max_ms'] > max_response_ms:
            max_response_ms = analysis['max_ms']
            max_response_ms_interval = interval
        
        # è®¡ç®—å“åº”æ—¶é—´æ¶åŒ–ç¨‹åº¦ - ç®€åŒ–ç‰ˆæœ¬ï¼ŒåŸºäºå¹³å‡å€¼å’Œæœ€å¤§å€¼çš„å…³ç³»
        if analysis['max_ms'] > analysis['avg_ms'] * 1.5:  # å¦‚æœæœ€å¤§å€¼æ˜æ˜¾é«˜äºå¹³å‡å€¼
            # å‡è®¾å‰åŠæ®µæ˜¯å¹³å‡å€¼ï¼ŒååŠæ®µæ˜¯æœ€å¤§å€¼é™„è¿‘çš„å€¼æ¥ä¼°ç®—æ¶åŒ–
            estimated_earlier_avg = analysis['avg_ms'] * 0.8
            estimated_recent_avg = analysis['max_ms'] * 0.9
            degradation_ratio = (estimated_recent_avg - estimated_earlier_avg) / estimated_earlier_avg if estimated_earlier_avg > 0 else 0
            
            if degradation_ratio > max_response_degradation:
                max_response_degradation = degradation_ratio
                max_response_interval = interval
                max_response_earlier_avg = estimated_earlier_avg
                max_response_recent_avg = estimated_recent_avg
    
    if max_response_interval and max_response_degradation > 0:
        print(f"    æœ€å¤§å“åº”è€—æ—¶å¢é•¿ç‡: {max_response_degradation*100:.1f}% å“åº”å˜åŒ–:{max_response_earlier_avg:.1f}ms->{max_response_recent_avg:.1f}ms å‘ç”Ÿæ—¶é—´:{max_response_interval['start_time'].strftime('%Y-%m-%d %H:%M:%S')} ~ {max_response_interval['end_time'].strftime('%Y-%m-%d %H:%M:%S')}")
    else:
        print("    æœ€å¤§å“åº”è€—æ—¶å¢é•¿ç‡: æ— æ˜æ˜¾æ¶åŒ–")
        
    if max_response_ms_interval:
        print(f"    æœ€å¤§å“åº”è€—æ—¶: {max_response_ms:.1f}ms å‘ç”Ÿæ—¶é—´:{max_response_ms_interval['start_time'].strftime('%Y-%m-%d %H:%M:%S')} ~ {max_response_ms_interval['end_time'].strftime('%Y-%m-%d %H:%M:%S')}")
    else:
        print("    æœ€å¤§å“åº”è€—æ—¶: æ— æ•°æ®")

def parse_time_arguments(args: List[str]) -> Tuple[datetime, datetime, int]:
    """è§£ææ—¶é—´å‚æ•°ï¼Œè¿”å›(å¼€å§‹æ—¶é—´, ç»“æŸæ—¶é—´, æ—¶é—´çª—å£ç§’æ•°)"""
    
    if len(args) == 3:
        # æ¨¡å¼1: IP + ç§’æ•°
        try:
            time_window = int(args[2])
            if time_window <= 0:
                raise ValueError("æ—¶é—´çª—å£å¿…é¡»å¤§äº0")
            
            max_seconds = CONFIG["max_time_range_hours"] * 3600
            if time_window > max_seconds:
                raise ValueError(f"æ—¶é—´çª—å£ä¸èƒ½è¶…è¿‡{CONFIG['max_time_range_hours']}å°æ—¶({max_seconds}ç§’)")
            
            time_till = datetime.now()
            time_from = time_till - timedelta(seconds=time_window)
            
            return time_from, time_till, time_window
            
        except ValueError as e:
            if "invalid literal" in str(e):
                raise ValueError("æ—¶é—´çª—å£å¿…é¡»æ˜¯æ•°å­—ï¼ˆç§’ï¼‰")
            else:
                raise e
    
    elif len(args) == 4:
        # æ¨¡å¼2: IP + å¼€å§‹æ—¶é—´ + ç»“æŸæ—¶é—´
        try:
            start_time_str = args[2]
            end_time_str = args[3]
            
            # è§£ææ—¶é—´å­—ç¬¦ä¸²
            time_from = datetime.strptime(start_time_str, "%Y-%m-%d %H:%M:%S")
            time_till = datetime.strptime(end_time_str, "%Y-%m-%d %H:%M:%S")
            
            # éªŒè¯æ—¶é—´èŒƒå›´
            if time_from >= time_till:
                raise ValueError("å¼€å§‹æ—¶é—´å¿…é¡»æ—©äºç»“æŸæ—¶é—´")
            
            duration = time_till - time_from
            max_duration = timedelta(hours=CONFIG["max_time_range_hours"])
            
            if duration > max_duration:
                raise ValueError(f"æ—¶é—´èŒƒå›´ä¸èƒ½è¶…è¿‡{CONFIG['max_time_range_hours']}å°æ—¶")
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯æœªæ¥æ—¶é—´
            now = datetime.now()
            if time_till > now:
                raise ValueError("ç»“æŸæ—¶é—´ä¸èƒ½æ˜¯æœªæ¥æ—¶é—´")
            
            time_window = int(duration.total_seconds())
            
            return time_from, time_till, time_window
            
        except ValueError as e:
            if "time data" in str(e):
                raise ValueError("æ—¶é—´æ ¼å¼é”™è¯¯ï¼Œåº”ä¸º: YYYY-MM-DD HH:MM:SS")
            else:
                raise e
    
    else:
        raise ValueError("å‚æ•°æ•°é‡é”™è¯¯")

def get_datacenter_by_ip(host_ip: str) -> str:
    """æ ¹æ®IPè·å–å¯¹åº”çš„æœºæˆ¿åç§°"""
    return IP_TO_DATACENTER.get(host_ip, "UNKNOWN")

def main():
    """ä¸»å‡½æ•°"""
    if len(sys.argv) not in [3, 4]:
        print("""ç”¨æ³•:
  æ¨¡å¼1 - æŒ‡å®šæ—¶é—´çª—å£: python firewall_simple_monitor.py <IP> <æ—¶é—´çª—å£ç§’æ•°>
  æ¨¡å¼2 - æŒ‡å®šæ—¶é—´èŒƒå›´: python firewall_simple_monitor.py <IP> <å¼€å§‹æ—¶é—´> <ç»“æŸæ—¶é—´>
  
ç¤ºä¾‹:
  python firewall_simple_monitor.py 192.168.1.1 3600
  python firewall_simple_monitor.py 192.168.1.1 "2024-01-15 10:00:00" "2024-01-15 12:00:00"
  
è¯´æ˜:
  - æ—¶é—´èŒƒå›´æœ€å¤šæ”¯æŒ6å°æ—¶
  - æ—¶é—´æ ¼å¼: YYYY-MM-DD HH:MM:SS""")
        sys.exit(1)
    
    host_ip = sys.argv[1]
    datacenter = get_datacenter_by_ip(host_ip)
    
    try:
        time_from, time_till, time_window = parse_time_arguments(sys.argv)
    except ValueError as e:
        print(f"é”™è¯¯ï¼š{e}")
        sys.exit(1)
    
    log_message(f"å¼€å§‹åˆ†æ - æœºæˆ¿:{datacenter}, IP:{host_ip}")
    log_message(f"æ—¶é—´èŒƒå›´: {time_from.strftime('%Y-%m-%d %H:%M:%S')} ~ {time_till.strftime('%Y-%m-%d %H:%M:%S')} (æ—¶é—´çª—å£:{time_window}ç§’)")
    
    # è·å–æµé‡æ•°æ®
    traffic_data = get_metrics_data(host_ip, TRAFFIC_METRICS, time_from, time_till)
    
    if not traffic_data:
        log_message("æµé‡æ•°æ®è·å–å¤±è´¥", "ERROR")
        sys.exit(1)
    
    # åˆ†ææµé‡è¶‹åŠ¿
    inbound_analysis = analyze_traffic_trend(traffic_data.get('inbound_traffic', []))
    outbound_analysis = analyze_traffic_trend(traffic_data.get('outbound_traffic', []))
    
    # æ”¶é›†æ‰€æœ‰é€’å¢åŒºé—´
    all_intervals = []
    
    for interval in inbound_analysis['increase_intervals']:
        interval['traffic_type'] = 'inbound'
        all_intervals.append(interval)
    
    for interval in outbound_analysis['increase_intervals']:
        interval['traffic_type'] = 'outbound'
        all_intervals.append(interval)
    
    if not all_intervals:
        print(f"ç»“è®ºï¼šæœºæˆ¿{datacenter}é˜²ç«å¢™{host_ip}æµé‡æ­£å¸¸ï¼Œæ— ä¸šåŠ¡å½±å“")
        sys.exit(0)
    
    # ç»Ÿè®¡å„ç±»å‹é€’å¢åŒºé—´æ•°é‡
    inbound_count = len(inbound_analysis['increase_intervals'])
    outbound_count = len(outbound_analysis['increase_intervals'])
    
    log_message(f"æ£€æµ‹åˆ°æµé‡é€’å¢åŒºé—´: å…¥æµé‡{inbound_count}ä¸ª, å‡ºæµé‡{outbound_count}ä¸ª, å¼€å§‹åˆ†æä¸šåŠ¡å½±å“...")
    
    # åˆ†æä¸šåŠ¡å½±å“
    impact_intervals = []
    
    for interval in all_intervals:
        impact_analysis = analyze_interval_impact(host_ip, interval)
        
        if impact_analysis['has_impact']:
            interval['business_impact'] = impact_analysis
            impact_intervals.append(interval)
    
    if not impact_intervals:
        print(f"ç»“è®ºï¼šæœºæˆ¿{datacenter}é˜²ç«å¢™{host_ip}è™½æœ‰æµé‡é€’å¢ï¼Œä½†æ— ä¸šåŠ¡å½±å“")
        sys.exit(0)
    
    # ç”ŸæˆæŠ¥å‘Š
    generate_report(datacenter, host_ip, time_window, impact_intervals, traffic_data, time_from, time_till)

if __name__ == "__main__":
    main() 